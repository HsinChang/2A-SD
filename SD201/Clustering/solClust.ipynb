{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE T_test: 1581.8549236255421\n"
     ]
    }
   ],
   "source": [
    "# Q3.1\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "points = []  # data\n",
    "stock_names = []  # names\n",
    "\n",
    "# most efficient to first build an array or dictionary and then convert it\n",
    "# to numpy. Numpy is not meant to add rows and columns dynamically, it is not efficient.\n",
    "stock_file=open('data.csv','r')        \n",
    "i=0\n",
    "for line in stock_file:\n",
    "    if (i==0):\n",
    "        i=1\n",
    "        continue\n",
    "    a=line.split(',')\n",
    "    stock_names.append(a[0])\n",
    "    vec=[]\n",
    "    for i in range(0,len(a)-1):\n",
    "        vec.append(a[i+1])\n",
    "    points.append(vec)\n",
    "    \n",
    "#convert it to numpy to use it with k-means clustering\n",
    "points=np.array(points, dtype='float32')\n",
    "\n",
    "n_class=8\n",
    "k_means = cluster.KMeans(n_clusters=n_class)\n",
    "k_means.fit(points)\n",
    "\n",
    "print 'SSE T_test:',k_means.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE T_test: 1522.2885832787106\n"
     ]
    }
   ],
   "source": [
    "# Q3.2\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "points = []  # data\n",
    "stock_names = []  # names\n",
    "\n",
    "def nor(points):\n",
    "    for i in range(0,len(points)):\n",
    "        points[i]=normalize(points[i][:,np.newaxis], axis=0).ravel()\n",
    "    return points\n",
    "\n",
    "def distanceSquare(a,b):\n",
    "    x=0\n",
    "    for i in range(0,len(a)):\n",
    "        x+=((a[i]-b[i])*(a[i]-b[i]))\n",
    "    return x\n",
    "\n",
    "\n",
    "# most efficient to first build an array or dictionary and then convert it\n",
    "# to numpy. Numpy is not meant to add rows and columns dynamically, it is not efficient.\n",
    "stock_file=open('data.csv','r')        \n",
    "i=0\n",
    "for line in stock_file:\n",
    "    if (i==0):\n",
    "        i=1\n",
    "        continue\n",
    "    a=line.split(',')\n",
    "    stock_names.append(a[0])\n",
    "    vec=[]\n",
    "    for i in range(0,len(a)-1):\n",
    "        vec.append(a[i+1])\n",
    "    points.append(vec)\n",
    "    \n",
    "# convert it to numpy to use it with k-means clustering\n",
    "points=np.array(points, dtype='float32')\n",
    "\n",
    "n_class=8\n",
    "k_means = cluster.KMeans(init='k-means++', n_clusters=n_class, max_iter=10000, n_init=1000)\n",
    "k_means.fit(points)\n",
    "\n",
    "print 'SSE T_test:',k_means.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 :  Kraft , [-2.73973   0.418535  1.1194    0.829346 -0.629111  1.65094   5.13709\n",
      "  0.782524 -1.65027   0.443599  0.610643 -1.66774  -0.821837  1.42857\n",
      " -1.98333   1.39114  -0.126143  2.01711  -0.754243  1.55945   2.16181\n",
      " -1.79471   3.22266   3.19432  -0.191022] ,\n",
      "Verizon , [ 2.15023    1.9153    -0.295223   2.75107   -0.217687   0.794777\n",
      "  0.264901   0.853759   0.279799  -0.774979   1.83876    0.247934\n",
      " -1.06832   -2.73937   -3.46789   -2.98222   -2.10226   -1.83511\n",
      "  0.0554631  1.71849    1.87991   -0.36051   -0.745033  -0.0536481\n",
      " -1.21538  ] ,\n",
      "IBM , [ 2.43855   1.74769   0.206113  1.68998  -0.593472  0.        1.69481\n",
      "  0.401998 -3.27004   0.513614  0.836897 -0.140176 -0.958971 -1.8709\n",
      " -2.01259   2.04082  -0.225033  2.21088  -0.326435  2.87998   3.02802\n",
      "  0.489097 -0.788653  0.908605  3.79122 ] ,\n",
      "The Home Depot , [ 0.658256  -1.22308    0.981194   0.266951   0.         3.19785\n",
      "  1.92256    2.69549   -2.49187   -0.322061   2.30388    1.84783\n",
      " -3.06979   -1.20192   -4.28413    5.0644    -0.0533618  0.265252\n",
      "  0.188425   3.11381   -0.888769  -2.32955   -5.64885    0.216626\n",
      "  1.50125  ] ,\n",
      "Procter & Gamble , [-2.57967    2.88523    1.0501     1.6372    -0.898204   0.0618716\n",
      "  3.48275   -0.771605  -0.720839  -0.822581  -2.97628    1.2197\n",
      " -1.00979    0.0459841 -1.35685    1.75466   -0.434293  -0.628239\n",
      " -1.22611   -0.131234  -1.14996    0.170834  -1.39652    2.97243\n",
      "  0.39604  ] ,\n",
      "Wal-Mart , [ 2.36505   2.57463  -0.575436 -0.344102 -0.364299 -0.1701    1.92234\n",
      "  0.217155 -1.58548   0.631458 -0.550285 -0.677724 -2.1166   -0.108932\n",
      " -2.22303   2.16216   0.439686  0.941974  0.618357  1.19853  -0.744021\n",
      " -0.2766   -3.82828   1.36438   1.12502 ] ,\n",
      "AT&T , [-3.40829    1.46723    0.         5.51344    0.935484   1.61823\n",
      " -0.325203   0.598592  -1.34181    1.82469   -0.717547   1.78763\n",
      " -0.687398  -1.07595   -2.63659   -0.385424  -0.0975927  0.854701\n",
      " -1.16814    0.278067   2.00584   -2.7965    -0.670904   0.673077\n",
      " -0.770578 ] ,\n",
      "Merck , [-2.70668   6.67656   0.        1.62876  -1.25443   1.02769   2.46437\n",
      " -0.363967 -1.81538  -0.818182 -2.09691   0.394657 -0.70028  -0.137212\n",
      " -1.56636  -8.13204   0.989802 -0.467836  2.67081   1.49579  -1.20156\n",
      "  2.92091  -1.70992   2.68624  -0.498973] ,\n",
      "McDonalds , [-1.3064     1.50356    2.34958    0.582396   0.110389   2.59853\n",
      "  1.61523    0.0788747 -4.08673    0.458235  -0.58309    2.71145\n",
      " -0.297767   0.382653  -1.93596   -0.255892  -0.35382    0.0260112\n",
      "  2.03999    2.38095    0.338753  -3.54086   -1.98815    1.61087\n",
      "  0.482251 ] ,\n",
      "Coca-Cola , [-1.04979   -0.721118   0.293686   3.09816   -1.59787    0.798771\n",
      "  1.13011    1.38213   -2.54896   -0.780772  -0.673092   1.43609\n",
      " -0.183178  -1.26919   -2.10636    0.685805   0.0743826  0.458783\n",
      "  1.62069    3.31063    0.385109  -4.49302    1.49937    1.97427\n",
      " -0.696092 ] ,\n",
      "SSE P: 573.9374039013601\n",
      "\n",
      "\n",
      "class 1 :  American Express , [-4.7557     4.00509    3.58155   -0.395257   0.768624   1.12594\n",
      " -0.237274  -1.91728    0.706794   0.957592  -0.0206825  6.34668\n",
      " -2.82923    1.68118   -4.10586    4.63801    1.46898    2.74809\n",
      " -0.0228676  1.87709   -0.70247    2.44804   -3.13752   -1.13863\n",
      " -0.0651749] ,\n",
      "Boeing , [-3.2019     5.65488   -1.44928    0.693878   0.574788   1.50561\n",
      " -1.42566    0.467675  -2.90853    0.0558659 -3.65062    0.99398\n",
      " -2.76886   -1.29434   -3.80463    0.93633    0.122649   3.74037\n",
      " -0.92452    4.33917    3.06093    4.88284   -0.0691085 -0.353045\n",
      "  1.15721  ] ,\n",
      "Microsoft , [-0.963597  1.40845  -1.88301  -0.701481  2.27179   1.97562  -3.13097\n",
      " -0.514706 -2.70694  -1.72216   0.537857 -1.97842  -0.83682  -0.269854\n",
      " -4.24679   0.35461   2.43615   1.67331  -2.77257   1.74742   0.\n",
      "  1.96078  -0.85885  -2.9845   -0.497159] ,\n",
      "Walt Disney , [-1.99294   1.79499   0.581677 -0.787219  0.899149 -1.52731  -0.574713\n",
      "  0.85668  -3.30675  -1.37836  -0.713342  6.39706  -1.73558  -0.943179\n",
      " -6.01432   0.717765 -2.58922   3.17305   1.23199   3.64206   4.27766\n",
      "  4.531     0.280177 -4.15512   1.71487 ] ,\n",
      "Intel , [ 2.0447     8.32943   -0.428816  -3.5225    -3.09773   -1.11993\n",
      " -1.59442    2.35784   -3.5334    -3.78054    0.0471921  0.0919963\n",
      " -1.92661    0.999131  -3.20713    1.78658    1.1622     9.88223\n",
      " -0.873563   2.36181    0.603248  -1.66587   -0.410023   1.21055\n",
      " -0.998573 ] ,\n",
      "General Electric , [ 1.35474   1.53923  -1.15869   2.67542   0.621118  0.983069 -0.988142\n",
      " -0.32543  -3.55711  -0.196078 -2.01745   2.6962   -2.08445  -3.33333\n",
      " -4.36992   1.12843  -2.60492   0.91047  -2.7685    0.355691  2.13612\n",
      " -0.3245   -0.287356 -0.400601  4.00421 ] ,\n",
      "United Technologies , [ 1.45776    2.96552   -1.08524    1.87463   -0.0925819  1.98987\n",
      " -1.82353   -0.0705302 -0.718355  -2.10767   -0.0355619  2.83645\n",
      " -0.277342  -0.910807  -4.32184    1.03488   -0.992295   5.44794\n",
      " -0.86145    2.73063    0.880196  -0.138906  -1.38396    0.112511\n",
      "  1.16044  ] ,\n",
      "Travelers , [ 1.21509    3.19635   -0.431862   1.04925   -0.356333  -2.02977\n",
      " -0.0835422  3.53501   -0.701214  -0.641242  -1.54594    2.91347\n",
      " -3.48818   -0.204531  -1.24294    2.84262   -0.417851   3.37154\n",
      " -0.704698   0.924025   2.86687   -4.92066   -1.65016   -1.42338\n",
      "  0.695716 ] ,\n",
      "JPMorgan Chase , [-1.48197   2.19485   0.372353  0.542299  0.919811 -1.18673  -4.48936\n",
      "  4.34783   0.704535  0.263043 -2.49383   4.06704  -0.121655 -1.95908\n",
      " -3.86216   3.79015   1.56114   0.926135 -2.75582  -0.907519  0.405314\n",
      "  1.48837  -1.10169  -3.57542   0.599733] ,\n",
      "3M , [-1.98408   3.514    -2.07243   0.768232  1.27858   0.702216 -0.822737\n",
      "  1.35194  -2.44491  -1.04774  -0.579742  4.11705   0.387254 -2.0291\n",
      " -3.56194   2.80047   0.58265   2.15358   0.31556   2.21558   0.409417\n",
      " -0.599424 -2.67443   0.745016  1.65073 ] ,\n",
      "Johnson & Johnson , [-4.07609    3.25216   -1.08417    0.8647     2.42368   -0.0452352\n",
      "  1.71313    0.692042  -1.54648   -2.2917    -1.54358   -0.295664\n",
      "  0.333991  -0.986044  -1.81251    0.417402  -0.0672269  5.98842\n",
      "  1.88553    0.528379   1.13032   -0.0479004 -1.71391    2.31915\n",
      "  0.723356 ] ,\n",
      "SSE P: 777.1920221011969\n",
      "\n",
      "\n",
      "class 2 :  Cisco Systems , [  0.431862    3.48494    -1.72414    -1.84332     0.304692   -1.12285\n",
      "  -3.83964     0.0530786  -3.76193    -2.23312    -0.0669344 -15.4229\n",
      "  -5.73566     0.285551   -3.49608     1.2894      3.76249     0.35545\n",
      "  -1.18153    -0.346021    5.35117     2.54279    -0.480513   -3.70793\n",
      "  -2.35627  ] ,\n",
      "SSE P: 9.468537065515648e-13\n",
      "\n",
      "\n",
      "class 3 :  Chevron , [-0.55384   1.92791   0.529256  1.80451   2.05676  -0.869652 -3.18936\n",
      "  3.37173   3.67084  -4.0242   -0.9911   -0.853207 -1.21903  -6.0285\n",
      " -3.45091   2.06707   1.0505    3.03001   1.43723   2.81148   3.47363\n",
      " -0.512765  2.89227  -0.83293   0.903809] ,\n",
      "Pfizer , [-0.981997   5.11278   -0.71977   -0.195886   2.14739    0.896414\n",
      " -0.0973236  1.96599    3.75321   -0.86558   -0.049776  -2.28334\n",
      " -3.41018   -2.79092   -0.761905   0.658617  -0.437956  -2.60827\n",
      "  3.7467     0.147638   6.10225    3.61582   -0.105932   1.89966\n",
      "  0.0544959] ,\n",
      "ExxonMobil , [ 0.177552  1.95851   1.68287   0.97782   3.00424  -1.225    -1.93136\n",
      "  3.04878  -1.00404  -4.33364  -2.37762  -0.754943 -1.42098  -6.14075\n",
      " -2.52161   3.60708   2.0057    3.91048  -0.919995  2.13754   4.2042\n",
      "  2.53663   0.435448 -2.578     1.52976 ] ,\n",
      "SSE P: 138.01837121450808\n",
      "\n",
      "\n",
      "class 4 :  Bank of America , [-4.5614   -0.324675 -2.60723  -0.372578  1.91805  -1.92837  -5.03704\n",
      " -0.13541  -1.54278   1.41044  -0.661001  1.79187  -3.39893  -0.404531\n",
      " -4.97051   7.62174   0.597015 -2.22399  -1.05116  -6.05634   4.23049\n",
      "  2.88809  -1.25174  -2.85016  -5.50398 ] ,\n",
      "SSE P: 9.43689570931383e-14\n",
      "\n",
      "\n",
      "class 5 :  Hewlett-Packard , [ -2.52731    -1.68047   -10.4975     -3.39463     3.87858    -0.370054\n",
      "  -1.10538     0.454076    0.0242072  -2.72727     0.316183    1.94928\n",
      "  -2.05613     0.294913   -3.13841     3.09853     0.123001    2.57758\n",
      "  -1.04505     1.62485     4.44836     6.79773   -10.2796     -0.931601\n",
      "   2.36238  ] ,\n",
      "SSE P: 6.507294703084199e-14\n",
      "\n",
      "\n",
      "class 6 :  Alcoa , [ 1.63831   0.354191 -4.35294   1.98482   3.25815  -3.72793  -8.52713\n",
      " -0.632547  1.00313  -3.31725   3.81731   0.230814 -4.0201   -0.694847\n",
      " -4.8416   -4.42849   2.87026   3.72861  -1.36823   4.33455   5.93325\n",
      "  3.79267  -1.76678  -0.34965  -2.47066 ] ,\n",
      "SSE P: 1.4943601911454607e-13\n",
      "\n",
      "\n",
      "class 7 :  DuPont , [ 3.81916   1.97522   0.        1.99593   1.56522  -0.919448 -1.00992\n",
      "  2.8288   -0.357277 -2.21811   4.9697    3.72482  -1.0338   -3.17263\n",
      " -5.43437   3.10559  -0.18018   3.00295  -0.645518  0.557621  4.74576\n",
      " -0.579421 -1.60146  -3.69494  -2.38239 ] ,\n",
      "Caterpillar , [ 3.20354   5.64811  -1.45461   3.26821   3.25765  -1.01104  -2.55408\n",
      "  2.22093   2.40764  -3.28757   3.64805   3.93495  -3.45137  -5.07571\n",
      " -4.99013   0.858277 -3.45495   3.63705   0.311526  2.04864   3.59929\n",
      " -0.688705 -2.72745  -4.0343   -1.49745 ] ,\n",
      "SSE P: 33.14081582869403\n",
      "\n",
      "\n",
      "SSE T_test: 1522.2885832787106\n",
      "\n",
      "\n",
      "SSE T_test_2: 1522.2886130457603\n"
     ]
    }
   ],
   "source": [
    "# Q3.3\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "points = []  # data\n",
    "stock_names = []  # names\n",
    "\n",
    "# most efficient to first build an array or dictionary and then convert it\n",
    "# to numpy. Numpy is not meant to add rows and columns dynamically, it is not efficient.\n",
    "stock_file=open('stock_data.csv','r')        \n",
    "i=0\n",
    "for line in stock_file:\n",
    "    if (i==0):\n",
    "        i=1\n",
    "        continue\n",
    "    a=line.split(',')\n",
    "    stock_names.append(a[0])\n",
    "    vec=[]\n",
    "    for i in range(0,len(a)-1):\n",
    "        vec.append(a[i+1])\n",
    "    points.append(vec)\n",
    "    \n",
    "# convert it to numpy to use it with k-means clustering\n",
    "points=np.array(points, dtype='float32')\n",
    "\n",
    "n_class=8\n",
    "k_means = cluster.KMeans(init='k-means++', n_clusters=n_class, max_iter=10000, n_init=1000)\n",
    "k_means.fit(points)\n",
    "\n",
    "sse=0\n",
    "for i in range(0,n_class):\n",
    "    print \"class\",i,\": \",\n",
    "    ssep=0\n",
    "    for j in range(0,len(points)):\n",
    "        if k_means.labels_[j]==i:\n",
    "            print stock_names[j],\",\",points[j],\",\"\n",
    "            ssep += distanceSquare(k_means.cluster_centers_[i],points[j])\n",
    "            sse += distanceSquare(k_means.cluster_centers_[i],points[j])\n",
    "    \n",
    "    print 'SSE P:',ssep\n",
    "    print \"\\n\"\n",
    "print 'SSE T_test:',k_means.inertia_\n",
    "print \"\\n\"\n",
    "print 'SSE T_test_2:',sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0 :  DuPont , [ 0.28212887  0.14591338  0.          0.14744326  0.11562588 -0.06792143\n",
      " -0.07460478  0.20896901 -0.02639275 -0.16385615  0.3671215   0.27515978\n",
      " -0.07636884 -0.23436843 -0.4014476   0.22941604 -0.01331025  0.22183383\n",
      " -0.04768568  0.04119256  0.35057864 -0.04280297 -0.118303   -0.2729525\n",
      " -0.17599183] ,\n",
      "Caterpillar , [ 0.20037554  0.35327888 -0.09098318  0.20442052  0.20376001 -0.06323869\n",
      " -0.15975301  0.13891509  0.15059344 -0.20563145  0.22817881  0.2461239\n",
      " -0.21587685 -0.3174763  -0.31212345  0.05368365 -0.21610077  0.22749078\n",
      "  0.01948538  0.12813866  0.22512896 -0.04307723 -0.17059697 -0.25233802\n",
      " -0.09366274] ,\n",
      "Verizon , [ 0.26161146  0.2330283  -0.03591882  0.3347137  -0.02648527  0.09669792\n",
      "  0.03222964  0.10387407  0.03404223 -0.09428916  0.22371593  0.03016532\n",
      " -0.12997901 -0.33329022 -0.42192686 -0.36283696 -0.25577512 -0.22327183\n",
      "  0.00674801  0.20908307  0.22872251 -0.04386207 -0.09064574 -0.00652719\n",
      " -0.14787132] ,\n",
      "SSE P: 0.6409838897670088\n",
      "\n",
      "\n",
      "class 1 :  IBM , [ 0.27581716  0.19767603  0.02331283  0.19114864 -0.06712586  0.\n",
      "  0.19169495  0.0454688  -0.36986455  0.05809336  0.09465894 -0.01585489\n",
      " -0.10846637 -0.21161196 -0.2276381   0.2308311  -0.02545282  0.2500661\n",
      " -0.0369221   0.32574603  0.34249038  0.05532032 -0.08920221  0.10276962\n",
      "  0.42881367] ,\n",
      "The Home Depot , [ 0.05479981 -0.10182142  0.0816844   0.02222367  0.          0.26622102\n",
      "  0.16005312  0.22439954 -0.20744818 -0.02681158  0.19179802  0.15383185\n",
      " -0.25556    -0.10005984 -0.35665384  0.42161134 -0.00444237  0.02208223\n",
      "  0.01568638  0.2592247  -0.07399002 -0.19393505 -0.4702668   0.01803412\n",
      "  0.12497907] ,\n",
      "Wal-Mart , [ 0.31697372  0.34506246 -0.07712229 -0.04611796 -0.04882485 -0.0227975\n",
      "  0.25763988  0.029104   -0.21249253  0.08463059 -0.07375145 -0.09083135\n",
      " -0.2836754  -0.01459951 -0.2979396   0.28978154  0.05892852  0.12624721\n",
      "  0.08287474  0.1606319  -0.09971675 -0.03707107 -0.5130818   0.1828598\n",
      "  0.1507798 ] ,\n",
      "General Electric , [ 0.12838577  0.14586948 -0.10980652  0.25354373  0.058862    0.09316331\n",
      " -0.09364407 -0.03084029 -0.33709958 -0.01858189 -0.19118935  0.25551298\n",
      " -0.1975388  -0.31589243 -0.41412777  0.10693885 -0.24686259  0.08628326\n",
      " -0.26236472  0.03370806  0.20243545 -0.03075216 -0.0272321  -0.03796408\n",
      "  0.37947026] ,\n",
      "SSE P: 1.3925263140383208\n",
      "\n",
      "\n",
      "class 2 :  Kraft , [-0.28877583  0.04411486  0.11798815  0.08741558 -0.0663102   0.17401408\n",
      "  0.54146487  0.0824804  -0.17394346  0.04675668  0.06436363 -0.17578484\n",
      " -0.08662411  0.15057561 -0.20904899  0.14663036 -0.01329585  0.21260951\n",
      " -0.0794995   0.16437076  0.22786132 -0.18916787  0.33967814  0.336691\n",
      " -0.0201343 ] ,\n",
      "Procter & Gamble , [-0.32200718  0.3601487   0.13107868  0.2043634  -0.11211827  0.00772312\n",
      "  0.43473408 -0.09631556 -0.08997869 -0.10267863 -0.371514    0.152249\n",
      " -0.12604697  0.00573996 -0.16936873  0.21902534 -0.0542106  -0.07841989\n",
      " -0.15304911 -0.01638128 -0.1435437   0.02132435 -0.17432053  0.37103343\n",
      "  0.04943567] ,\n",
      "AT&T , [-0.37818906  0.16280608  0.          0.61177975  0.10380273  0.17956127\n",
      " -0.03608502  0.06642068 -0.14888929  0.20247039 -0.07962011  0.19835815\n",
      " -0.07627473 -0.11938906 -0.29256004 -0.04276723 -0.01082903  0.09483892\n",
      " -0.1296186   0.03085474  0.22257107 -0.3103039  -0.07444453  0.07468565\n",
      " -0.08550452] ,\n",
      "Merck , [-0.2064216   0.5091796   0.          0.12421536 -0.09566756  0.07837551\n",
      "  0.18794213 -0.02775749 -0.1384477  -0.06239764 -0.15991825  0.03009803\n",
      " -0.05340599 -0.0104643  -0.11945651 -0.62017995  0.07548603 -0.03567893\n",
      "  0.20368601  0.11407457 -0.09163549  0.22275957 -0.13040493  0.20486276\n",
      " -0.03805356] ,\n",
      "McDonalds , [-0.14863928  0.17107171  0.26733     0.06626372  0.01255982  0.29565498\n",
      "  0.18377727  0.00897419 -0.46497905  0.05213696 -0.06634268  0.30850276\n",
      " -0.03387927  0.04353741 -0.22026923 -0.02911482 -0.04025685  0.0029595\n",
      "  0.23210552  0.2708992   0.03854256 -0.40287116 -0.22620729  0.18328121\n",
      "  0.05486945] ,\n",
      "Coca-Cola , [-0.12152096 -0.08347474  0.03399633  0.35863495 -0.18496527  0.09246366\n",
      "  0.13081859  0.15999177 -0.29506096 -0.09038013 -0.07791538  0.16623804\n",
      " -0.02120421 -0.14691813 -0.24382675  0.079387    0.00861034  0.05310753\n",
      "  0.18760686  0.3832299   0.04457922 -0.5201003   0.17356317  0.22853635\n",
      " -0.0805778 ] ,\n",
      "SSE P: 3.036134929885762\n",
      "\n",
      "\n",
      "class 3 :  Bank of America , [-0.2763342  -0.01966914 -0.15794861 -0.02257115  0.1161974  -0.11682259\n",
      " -0.30514896 -0.00820327 -0.09346316  0.08544587 -0.04004411  0.10855328\n",
      " -0.2059106  -0.02450689 -0.3011185   0.46173266  0.03616777 -0.13473155\n",
      " -0.06368033 -0.36689916  0.25628734  0.17496338 -0.07583167 -0.17266555\n",
      " -0.33343664] ,\n",
      "JPMorgan Chase , [-0.12818153  0.18984137  0.0322063   0.04690561  0.07955815 -0.10264504\n",
      " -0.38830274  0.37606126  0.06093806  0.02275164 -0.21570136  0.3517746\n",
      " -0.01052243 -0.16944869 -0.33405373  0.32782528  0.13502926  0.08010513\n",
      " -0.23836194 -0.07849496  0.03505724  0.1287351  -0.0952896  -0.3092524\n",
      "  0.05187332] ,\n",
      "SSE P: 0.4235635740078578\n",
      "\n",
      "\n",
      "class 4 :  Chevron , [-0.04352232  0.15150064  0.04159044  0.14180352  0.16162604 -0.06833972\n",
      " -0.25062895  0.2649601   0.28846502 -0.31623307 -0.07788345 -0.06704742\n",
      " -0.09579484 -0.47373664 -0.2711823   0.16243623  0.08255128  0.23810679\n",
      "  0.11294162  0.22093408  0.2729677  -0.04029453  0.22728279 -0.06545401\n",
      "  0.07102387] ,\n",
      "Pfizer , [-0.0795395   0.41412345 -0.05829972 -0.01586632  0.17393364  0.07260747\n",
      " -0.00788299  0.15924066  0.3040014  -0.07010999 -0.00403174 -0.18494529\n",
      " -0.27621675 -0.22605811 -0.06171256  0.05334647 -0.03547343 -0.21126387\n",
      "  0.3034741   0.01195834  0.49426824  0.2928731  -0.00858025  0.1538681\n",
      "  0.00441404] ,\n",
      "ExxonMobil , [ 0.01344737  0.14833297  0.12745664  0.0740578   0.2275341  -0.09277863\n",
      " -0.14627668  0.23090746 -0.07604364 -0.32821977 -0.18007538 -0.05717762\n",
      " -0.1076217  -0.465086   -0.19098084  0.27319178  0.15190703  0.2961706\n",
      " -0.06967827  0.16189228  0.31841624  0.1921184   0.03297981 -0.19525169\n",
      "  0.11586044] ,\n",
      "SSE P: 0.8527461944398738\n",
      "\n",
      "\n",
      "class 5 :  Intel , [ 0.12651534  0.5153816  -0.02653289 -0.2179539  -0.19167134 -0.06929542\n",
      " -0.09865438  0.14589083 -0.21862833 -0.23392007  0.00292     0.00569225\n",
      " -0.11920856  0.06182101 -0.19844045  0.11054423  0.07191087  0.61146075\n",
      " -0.05405151  0.14613646  0.03732584 -0.10307533 -0.02537008  0.0749025\n",
      " -0.06178648] ,\n",
      "United Technologies , [ 0.1461401   0.29729268 -0.10879506  0.18793122 -0.00928131  0.199484\n",
      " -0.18280846 -0.00707064 -0.07201492 -0.21129344 -0.00356507  0.28435346\n",
      " -0.02780347 -0.09130819 -0.43326345  0.10374649 -0.09947735  0.54615474\n",
      " -0.08636016  0.27374503  0.08823945 -0.01392529 -0.13874167  0.0112792\n",
      "  0.11633384] ,\n",
      "Travelers , [ 0.11385171  0.29949215 -0.04046468  0.0983128  -0.03338775 -0.19018573\n",
      " -0.00782775  0.33122396 -0.06570247 -0.0600832  -0.14485174  0.2729868\n",
      " -0.32683608 -0.01916418 -0.1164612   0.26634827 -0.03915187  0.31590712\n",
      " -0.06602892  0.08657945  0.26862046 -0.46105683 -0.15461697 -0.1333681\n",
      "  0.06518731] ,\n",
      "Johnson & Johnson , [-0.40186286  0.32063138 -0.10688863  0.08525102  0.23895131 -0.00445975\n",
      "  0.16889797  0.06822862 -0.15246789 -0.22593935 -0.152182   -0.0291496\n",
      "  0.03292827 -0.09721436 -0.17869587  0.04115178 -0.00662792  0.59040004\n",
      "  0.18589494  0.05209304  0.11143856 -0.00472251 -0.16897488  0.22864565\n",
      "  0.07131588] ,\n",
      "SSE P: 1.3851416258330573\n",
      "\n",
      "\n",
      "class 6 :  American Express , [-0.35546327  0.29935917  0.26770177 -0.02954336  0.05745055  0.08415802\n",
      " -0.01773497 -0.14330646  0.05282909  0.0715749  -0.00154591  0.47438055\n",
      " -0.21146989  0.12565926 -0.30689117  0.34666654  0.10979843  0.2054051\n",
      " -0.00170923  0.14030248 -0.05250589  0.18297796 -0.23451291 -0.08510653\n",
      " -0.00487148] ,\n",
      "Boeing , [-0.2488906   0.43956602 -0.11265566  0.05393663  0.04467951  0.11703431\n",
      " -0.11081962  0.03635339 -0.2260863   0.00434258 -0.28377056  0.0772642\n",
      " -0.21522947 -0.10061184 -0.2957421   0.07278295  0.00953377  0.29074702\n",
      " -0.07186493  0.33729303  0.23793268  0.3795537  -0.00537195 -0.02744295\n",
      "  0.08995242] ,\n",
      "Walt Disney , [-0.14167526  0.12760328  0.04135059 -0.05596228  0.06391922 -0.10857429\n",
      " -0.04085553  0.06090016 -0.23507214 -0.09798565 -0.05071047  0.45475787\n",
      " -0.1233799  -0.06704925 -0.42754942  0.05102489 -0.18406396  0.2255676\n",
      "  0.08758041  0.25890884  0.30409274  0.32210234  0.01991738 -0.29538155\n",
      "  0.12190766] ,\n",
      "3M , [-0.20259804  0.35882097 -0.21161962  0.07844558  0.13055815  0.07170457\n",
      " -0.08401118  0.13804908 -0.24965425 -0.10698665 -0.05919852  0.42039955\n",
      "  0.03954322 -0.20719512 -0.3637162   0.28596115  0.05949546  0.219906\n",
      "  0.03222241  0.22623694  0.04180632 -0.06120829 -0.27309093  0.07607495\n",
      "  0.16855907] ,\n",
      "SSE P: 1.1646923493958639\n",
      "\n",
      "\n",
      "class 7 :  Cisco Systems , [ 0.02135144  0.17229694 -0.08524223 -0.09113454  0.0150641  -0.05551419\n",
      " -0.18983346  0.00262423 -0.18599145 -0.11040641 -0.00330927 -0.7625148\n",
      " -0.2835735   0.01411777 -0.1728477   0.06374849  0.18601914  0.0175736\n",
      " -0.05841535 -0.01710743  0.26456416  0.12571663 -0.02375677 -0.18332167\n",
      " -0.11649501] ,\n",
      "Microsoft , [-0.10006841  0.14626586 -0.19554836 -0.07284797  0.2359227   0.20516579\n",
      " -0.3251475  -0.05345161 -0.2811125  -0.17884427  0.05585581 -0.20545657\n",
      " -0.08690277 -0.02802402 -0.4410241   0.03682583  0.2529913   0.17377126\n",
      " -0.2879281   0.18146749  0.          0.20362468 -0.08919055 -0.30993676\n",
      " -0.05162937] ,\n",
      "Alcoa , [ 0.09284163  0.0200717  -0.24667741  0.11247806  0.1846366  -0.21125862\n",
      " -0.4832252  -0.0358459   0.05684652 -0.18798573  0.21632372  0.01308003\n",
      " -0.22781564 -0.03937639 -0.27436936 -0.25095877  0.16265519  0.21129715\n",
      " -0.07753643  0.24563526  0.33623222  0.21492738 -0.10012192 -0.01981437\n",
      " -0.1400102 ] ,\n",
      "Hewlett-Packard , [-0.13118464 -0.08722786 -0.5448919  -0.17620446  0.20132478 -0.01920833\n",
      " -0.05737677  0.02356964  0.00125652 -0.14156392  0.01641206  0.10118093\n",
      " -0.10672718  0.015308   -0.1629049   0.16083486  0.00638459  0.133794\n",
      " -0.05424523  0.0843408   0.23090024  0.3528486  -0.5335814  -0.04835645\n",
      "  0.12262364] ,\n",
      "SSE P: 1.673198578014393\n",
      "\n",
      "\n",
      "SSE T_test: 10.568987398911938\n",
      "\n",
      "\n",
      "SSE T: 10.568987455382137\n"
     ]
    }
   ],
   "source": [
    "# Q3.4\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import cluster\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "points = []  # data\n",
    "stock_names = []  # names\n",
    "\n",
    "# most efficient to first build an array or dictionary and then convert it\n",
    "# to numpy. Numpy is not meant to add rows and columns dynamically, it is not efficient.\n",
    "stock_file=open('data.csv','r')        \n",
    "i=0\n",
    "for line in stock_file:\n",
    "    if (i==0):\n",
    "        i=1\n",
    "        continue\n",
    "    a=line.split(',')\n",
    "    stock_names.append(a[0])\n",
    "    vec=[]\n",
    "    for i in range(0,len(a)-1):\n",
    "        vec.append(a[i+1])\n",
    "    points.append(vec)\n",
    "\n",
    "# convert it to numpy to use it with k-means clustering\n",
    "# vectors are also normalized.\n",
    "points=np.array(points, dtype='float32')\n",
    "points=nor(points)\n",
    "\n",
    "n_class=8\n",
    "k_means = cluster.KMeans(init='random', n_clusters=n_class, max_iter=10000, n_init=10000)\n",
    "k_means.fit(points)\n",
    "sse=0\n",
    "for i in range(0,n_class):\n",
    "    print \"class\",i,\": \",\n",
    "    ssep=0\n",
    "    for j in range(0,len(points)):\n",
    "        if k_means.labels_[j]==i:\n",
    "            print stock_names[j],\",\",points[j],\",\"\n",
    "            ssep += distanceSquare(k_means.cluster_centers_[i],points[j])\n",
    "            sse += distanceSquare(k_means.cluster_centers_[i],points[j])\n",
    "    \n",
    "    print 'SSE P:',ssep\n",
    "    print \"\\n\"\n",
    "print 'SSE T_test:',k_means.inertia_\n",
    "print \"\\n\"\n",
    "print 'SSE T:',sse\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kraft, McDonald, Coca Cola, Kraft about food. Procter and Gamble was also selling food before 2014 (the data comes from there. ) AT&T, Merck outliers. \n",
    "Bank of America, JPMorgan Chase, banking and investment\n",
    "cluster Oil, Chevron Exxon Mobil, Pfizer seems to be an outlier\n",
    "cluster technology: Microsoft, HP, Alcoa, Cisco.  Alcoa sells aluminium so it is somehow related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3.5\n",
    "\n",
    "Run it with a larger number of clusters and split looser clusters. Run it with a smaller number of clusters and merge the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
